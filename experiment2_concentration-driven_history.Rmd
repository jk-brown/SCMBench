---
title: "Experiment 2 - Concentration History"
author: "Joe Brown"
date: "2025-05-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Goal

The goal for this file is to begin by running Hector + Matilda in concentration-driven mode in history and then switching to emissions-driven future. This means that we will be constraining history to CO2 concentrations and then using emissions with the carbon cycle and perturbed parameters to make future projections.

# Set-up

## Load libraries and utils 

```{r, message=FALSE}

source("set-up/libraries.R")
source("set-up/utils.R")

```

## Load ini files

```{r}

source("set-up/load_ini.R")

```

## Load perturbed parameter data frame

This step loads a pre-generated perturbed parameter ensemble (PPE) that will be used across all Hector + Matilda experiments. The PPE was generated once using Hector defaults and saved to ensure consistent sampling across model configurations. Parameters are automatically "chunked" for parallel processing.

```{r}

source("set-up/load_params.R")

```


Experiment 2 Running the model: Constrained to C02 in history with emissions driven future

The goal here is to run Hector + Matilda in "concentration-driven" mode by constraining historical CO2 concentrations.

## Load CO2 data for constraint

```{r}
# scenario names
ssp_scenarios <- c("ssp119", "ssp126", "ssp245", "ssp370", "ssp585")
# directory where constraint data are saved
constraint_dir <- here("data", "processed")

# Load scenario specific co2 constraint data
constraint_data_list <- lapply(ssp_scenarios, function(ssp) {
  
  read.csv(file.path(constraint_dir, paste0(ssp, "_CO2_constraint-historical.csv")))
  
})

# edit list names
names(constraint_data_list) <- names(ini_list)
```
## Run model 

Run Hector over entire PPE for each SSP scenario in the scenario list

```{r}
start_time <- Sys.time()
matilda_result_exp2 <- matilda_conc_driven(param_chunks, ini_list, constraint_data_list)
end_time <- Sys.time()

elapsed_time <- end_time - start_time
print(elapsed_time)

```

Correct the run_numbers for each of element in the result list

```{r}

matilda_result_exp2 <- fix_run_numbers(matilda_result_exp2)

```

## Check for and deal with NAs

Get the runs that produced NAs:
```{r}

lapply(matilda_result_exp2, function(df) {
  
  get_na_runs(df, verbose = T)
  
})

```

Remove NAs if desired:
```{r}

matilda_result_exp2 <- lapply(matilda_result_exp2, function(df) {
  
  remove_na_runs(df, verbose = T)
  
})

```

# Save model runs 

```{r}
# define directory path
result_dir <- here("output", "model_results")

# create directory if one does not exist
if (!dir.exists(result_dir)) {
  dir.create(result_dir, recursive = T)
}

# identify the file path
file_name <- "exp2_matilda_results_concentration_historic_NA-rm.RDS"
file_path <- file.path(result_dir, file_name)

# save 
saveRDS(matilda_result_exp2, file_path)
```

# Normalize to 1995-2014 reference period 

```{r}

matilda_result_exp2_norm_gsat <- lapply(matilda_result_exp2, function(df) {
  
  normalize_to_reference(df, 1995, 2014, variables = "global_tas")

  })

```

# Compute median warming for each 

Here we want to compute the probability distribution of warming.

Create new metric object fo late century (lc) warming:
```{r}
# creating median end-of-century warming (GSAT)
lc_warming <- new_metric(GLOBAL_TAS(), 2081:2100, median)

```

Use the lc_warming metric to compute median late century warming for each run:
```{r}
# computing median end-of-century warming
lc_warming_values_exp2 <- lapply(names(matilda_result_exp2_norm_gsat), function(scenario_name) {
  
  df <- matilda_result_exp2_norm_gsat[[scenario_name]]
   
  metric_values <- metric_calc(df, lc_warming)
  
  metric_values$scenario <- scenario_name
  
  return(metric_values)
   
 })

```

Make a gsat metrics data frame for save and prelim visualization:
```{r}

gsat_metrics_exp2_df <- do.call(rbind, lc_warming_values_exp2)

```

Save the late century metrics data frame:

```{r}
# define directory path
result_dir <- here("output", "warming_results")

# create directory if one does not exist
if (!dir.exists(result_dir)) {
  dir.create(result_dir, recursive = T)
}

# identify the file path
file_name <- "exp2_gsat_metric.csv"
file_path <- file.path(result_dir, file_name)

# save 
write.csv(gsat_metrics_exp2_df, file_path, row.names = FALSE)

```

Preliminary visualization of warming PDF. Here we want to plot a weighted PDF curve with a facet for scenario:
```{r}

ggplot(gsat_metrics_exp2_df, aes(x = metric_result)) +
  stat_density(geom = "line", color = "dodgerblue", size = 1.2, adjust = 1) +
  labs(
    title = " Warming Distribution",
    x = "Late Century Warming (Â°C)",
    y = "Density"
  ) +
  theme_light() +
  facet_wrap(~scenario)

```
OKAY that works -- and I will want to overlay the other experiments to show how the warming distribution is affected by the historical configuration. 


## Computing probabilities 

Here I want to compute probabilities for a range of different temperatures.

```{r}
names(lc_warming_values_exp2) <- names(matilda_result_exp2)

# define bins that represent the temperature ranges of interest
temp_ranges <- c(0, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, Inf)

# computing probabilities
temp_prob_exp2 <- lapply(names(lc_warming_values_exp2), function(df_name) {
  
  # copy data 
  df <- lc_warming_values_exp2[[df_name]]
  
  # run probability calculator
  prob_result <- prob_calc(df$metric_result, 
                           bins = temp_ranges)
  
  # add scenario column to the result
  prob_result$scenario <- df_name
  
  return(prob_result)
})

# give element names 
names(temp_prob_exp2) <- names(matilda_result_exp2)

```

Save probability data:

```{r}
# define directory path
result_dir <- here("output", "probability_results")

# create directory if one does not exist
if (!dir.exists(result_dir)) {
  dir.create(result_dir, recursive = T)
}

# identify the file path
file_name <- "exp2_gsat_probability.rds"
file_path <- file.path(result_dir, file_name)

# save 
saveRDS(temp_prob_exp2, file_path)
```

Create a probability df and save:
```{r}
exp2_probability_df <- do.call(rbind, temp_prob_exp2)

# define directory path
result_dir <- here("output", "probability_results")

# create directory if one does not exist
if (!dir.exists(result_dir)) {
  dir.create(result_dir, recursive = T)
}

# identify the file path
file_name <- "exp2_gsat_probability.csv"
file_path <- file.path(result_dir, file_name)

# save 
write.csv(exp2_probability_df, file_path, row.names = FALSE)
```
